---
_schema: default
id: 168202
date: 2025-02-03
title: >-
    List three common evaluation metrics used in supervised learning.
article_title: >-
    List three common evaluation metrics used in supervised learning.
date_format: MMM DD, YYYY
post_on_text: Posted on
seo:
  title: QuickTakes | Others
  page_description: >-
    This content discusses three common evaluation metrics used in supervised learning: accuracy, precision, and recall, highlighting their formulas, significance, and use cases.
  page_keywords: >-
    supervised learning,evaluation metrics,accuracy,precision,recall,class imbalance,model performance,classification tasks
author: QuickTakes
question: >-
    List three common evaluation metrics used in supervised learning.
answer: >-
    In supervised learning, evaluation metrics are essential for assessing the performance of models. Here are three common evaluation metrics used in this context:\n\n1. **Accuracy**: This metric measures the proportion of correctly predicted instances out of the total instances. It is calculated as:\n   $$\n   \text{Accuracy} = \frac{\text{TP} + \text{TN}}{\text{TP} + \text{TN} + \text{FP} + \text{FN}}\n   $$\n   where TP is true positives, TN is true negatives, FP is false positives, and FN is false negatives. Accuracy is a straightforward metric but can be misleading in cases of class imbalance.\n\n2. **Precision**: Precision indicates the accuracy of positive predictions. It is defined as the ratio of true positives to the sum of true positives and false positives:\n   $$\n   \text{Precision} = \frac{\text{TP}}{\text{TP} + \text{FP}}\n   $$\n   This metric is particularly useful when the cost of false positives is high.\n\n3. **Recall (Sensitivity)**: Recall measures the ability of a model to find all the relevant cases (true positives). It is calculated as:\n   $$\n   \text{Recall} = \frac{\text{TP}}{\text{TP} + \text{FN}}\n   $$\n   Recall is crucial in scenarios where missing a positive instance is more critical than false positives, such as in medical diagnoses.\n\nThese metrics provide a comprehensive view of model performance, especially in classification tasks, and help in making informed decisions about model selection and tuning.
subject: Others
file_name: list-three-common-evaluation-metrics-used-in-supervised-learning.md
url: /learn/others/questions/list-three-common-evaluation-metrics-used-in-supervised-learning
score: -1.0
related_article1:
    id: 168200
    title: >-
        Name two popular tools or libraries used for data augmentation.
    subject: Others
    url: /learn/others/questions/name-two-popular-tools-or-libraries-used-for-data-augmentation
related_article2:
    id: 168213
    title: >-
        What is the purpose of decision trees in prescriptive analysis?
    subject: Others
    url: /learn/others/questions/what-is-the-purpose-of-decision-trees-in-prescriptive-analysis
related_article3:
    id: 168198
    title: >-
        Why is quality control important in data annotation?
    subject: Others
    url: /learn/others/questions/why-is-quality-control-important-in-data-annotation
related_article4:
    id: 168208
    title: >-
        What are some common applications of sentiment analysis?
    subject: Others
    url: /learn/others/questions/what-are-some-common-applications-of-sentiment-analysis
related_article5:
    id: 168216
    title: >-
        What are the key benefits of using cloud computing in data science?
    subject: Others
    url: /learn/others/questions/what-are-the-key-benefits-of-using-cloud-computing-in-data-science
---

&nbsp;